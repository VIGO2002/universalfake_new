# log dir 
log_dir: /root/autodl-tmp/logs

# model setting
pretrained: 'no need to provide this for the effort model'
model_name: effort   # model name
backbone_name: vit  # backbone name

#backbone setting
backbone_config:
  mode: original
  num_classes: 2
  inc: 3
  dropout: false

# dataset
all_dataset: [FaceForensics++, FF-F2F, FF-DF, FF-FS, FF-NT, FaceShifter, DeepFakeDetection, Celeb-DF-v1, Celeb-DF-v2, DFDCP, DFDC, DeeperForensics-1.0, UADFV]
train_dataset: [FaceForensics++]
test_dataset: [Celeb-DF-v2, FaceShifter, DeeperForensics-1.0]

compression: c23  # compression-level for videos
train_batchSize: 32   # training batch size
test_batchSize: 64   # test batch size
workers: 16   # number of data loading workers
frame_num: {'train': 8, 'test': 8}   # number of frames to use per video in training and testing
resolution: 224   # resolution of output image to network
with_mask: false   # whether to include mask information in the input
with_landmark: false   # whether to include facial landmark information in the input


# data augmentation
use_data_augmentation: true  # Add this flag to enable/disable data augmentation
data_aug:
  flip_prob: 0.5
  rotate_prob: 0.5
  rotate_limit: [-10, 10]
  blur_limit: [3, 7]
  brightness_prob: 0.5
  brightness_limit: [-0.1, 0.1]
  contrast_limit: [-0.1, 0.1]
  quality_lower: 40
  quality_upper: 100

# mean and std for normalization
mean: [0.48145466, 0.4578275, 0.40821073]
std: [0.26862954, 0.26130258, 0.27577711]

# optimizer config
optimizer:
  # choose between 'adam' and 'sgd'
  type: adam
  adam:
    lr: 0.0004  # learning rate
    beta1: 0.9  # beta1 for Adam optimizer
    beta2: 0.999 # beta2 for Adam optimizer
    eps: 0.00000001  # epsilon for Adam optimizer
    weight_decay: 0.0005  # weight decay for regularization
    amsgrad: false
  sgd:
    lr: 0.0004  # learning rate
    momentum: 0.9  # momentum for SGD optimizer
    weight_decay: 0.0005  # weight decay for regularization

# training config
lr_scheduler: cosine       # <--- 修改这里：开启余弦退火
lr_T_max: 10               # <--- [必须新增] 周期长度，通常等于 nEpochs
lr_eta_min: 0.000001       # <--- [必须新增] 最小学习率 (1e-6)，衰减到这里停止
nEpochs: 10   # number of epochs to train for
start_epoch: 0   # manual epoch number (useful for restarts)
save_epoch: 1   # interval epochs for saving models
rec_iter: 100   # interval iterations for recording
logdir: ./logs   # folder to output images and logs
manualSeed: 1024   # manual seed for random number generation
save_ckpt: true   # whether to save checkpoint
save_feat: true   # whether to save features

# loss function
loss_func: cross_entropy   # loss function to use
losstype: null

# metric
metric_scoring: video_auc  # 改为 Video-level AUC

# cuda
ngpu: 1   # number of GPUs to use
cuda: true   # whether to use CUDA acceleration
cudnn: true   # whether to use CuDNN for convolution operations

save_avg: true
# [必须添加] 覆盖默认的错误路径
dataset_root_rgb: /root/autodl-tmp
dataset_json_folder: /root/autodl-tmp/Effort-AIGI-Detection/DeepfakeBench/preprocessing/dataset_json

# [新增] 泛化性增强模块配置 (Robust Manifold Regularization)
use_noise_injection: True   # 开启噪声注入
noise_std: 0.02             # 噪声强度 (建议 0.01)
